{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef83932b-880f-4f90-94cd-8fb5c12778a4",
   "metadata": {},
   "source": [
    "# Prepare data for finetuning the U-Net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "509c6db1-b112-4d49-adef-585b58b2c37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfb3e2ee-2e22-43bc-b323-23ef4a07742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbt_path = \"C:/Users/holgerv/WBT\"\n",
    "if wbt_path not in sys.path:\n",
    "    sys.path.insert(1, wbt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1e28d8d-e0c5-4561-9f38-5b0bed320700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from whitebox_tools import WhiteboxTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8d548e8-382b-4a18-a195-89fd7ef630b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "whitebox = WhiteboxTools()\n",
    "whitebox.set_whitebox_dir(wbt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e52993c3-12ab-488e-af69-f3222def741e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whitebox.set_verbose_mode(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "109f4171-1114-4aa4-981c-94910d5df933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whitebox.set_compress_rasters(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "323d15b8-6fe2-481a-bc85-5b1f4febe9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = \"D:/users/holgerv/Ditches\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2dac6a5-f067-4f7e-b46a-11b1ad57a40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetuning data directory\n",
    "finetuning_dir = f\"{basepath}/working/deep_learning/data/finetuning\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaff515-df37-4041-8bfa-7ff5e318f6e9",
   "metadata": {},
   "source": [
    "## Create model input grid cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c79448af-25ea-4f18-8305-d5089b71436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid cells from input GeoDataFrame bounds\n",
    "def create_grid_from_bounds(in_gdf: gpd.GeoDataFrame, grid_size: int, interval: int) -> gpd.GeoDataFrame:\n",
    "    \n",
    "    # Total bounds of input GeoDataFrame\n",
    "    xmin, ymin, xmax, ymax = in_gdf.total_bounds\n",
    "    \n",
    "    # Create list of grid cell polygons\n",
    "    grid_cells = []\n",
    "    for x in range(int(xmin), int(xmax), interval):\n",
    "        for y in range(int(ymin), int(ymax), interval):\n",
    "            if x + grid_size <= xmax:\n",
    "                if y + grid_size <= ymax:\n",
    "                    grid_cells.append(box(x, y, x + grid_size, y + grid_size))\n",
    "                    \n",
    "    # Create GeoDataFrame\n",
    "    out_gdf = gpd.GeoDataFrame(grid_cells, columns=[\"geometry\"], crs=in_gdf.crs)\n",
    "    \n",
    "    # Add ID column\n",
    "    out_gdf[\"tile_id\"] = out_gdf.index + 1\n",
    "    \n",
    "    return out_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d8b0b5e-59eb-4928-b1fa-bb68cd94f61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input DEM cell size\n",
    "cell_size = 1\n",
    "\n",
    "# Output grid size\n",
    "grid_size = int(500 * cell_size)\n",
    "\n",
    "# Grid cell interval\n",
    "interval = grid_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "732b9a5f-49b2-43ba-a3fe-88e324e477de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 266 ms\n",
      "Wall time: 2.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Loop over map sheets\n",
    "map_sheets = [53972, 54591]\n",
    "for map_sheet in map_sheets:\n",
    "    \n",
    "    # Read existing tiles\n",
    "    fp = f\"{basepath}/working/deep_learning/data/estonia_digitization/{map_sheet}/{map_sheet}_grid_{grid_size}m_digitization.gpkg\"\n",
    "    in_gdf = gpd.read_file(fp)\n",
    "    \n",
    "    # Create new tiles\n",
    "    out_gdf = create_grid_from_bounds(in_gdf, grid_size, interval)\n",
    "\n",
    "    # Add map sheet number to tile ID\n",
    "    out_gdf[\"tile_id\"] = f\"{map_sheet}_\" + out_gdf[\"tile_id\"].astype(str)\n",
    "    \n",
    "    # Write to GPKG\n",
    "    out_gdf.to_file(f\"{finetuning_dir}/{map_sheet}_grid_{grid_size}m_model.gpkg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9226099c-a2d3-4047-ae8b-0dd44b69a40f",
   "metadata": {},
   "source": [
    "## Split DEM to tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e3c8995-787d-405c-b30d-1750aae9dd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory\n",
    "out_dirpath = f\"{finetuning_dir}/dem\"\n",
    "if os.path.exists(out_dirpath):\n",
    "    shutil.rmtree(out_dirpath)\n",
    "os.mkdir(out_dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ddb0aff-94d5-48e4-aec0-d9fb40482909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input DEM cell size\n",
    "cell_size = 1\n",
    "\n",
    "# Output grid size\n",
    "grid_size = int(500 * cell_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eed9651e-02e5-4df5-a5bb-7275dc3da01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:09<00:00,  3.63it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.27 s\n",
      "Wall time: 20 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Loop over map sheets\n",
    "map_sheets = [53972, 54591]\n",
    "for map_sheet in map_sheets:\n",
    "    \n",
    "    # Read tiles\n",
    "    fp = f\"{finetuning_dir}/{map_sheet}_grid_{grid_size}m_model.gpkg\"\n",
    "    tiles = gpd.read_file(fp)\n",
    "    \n",
    "    # Loop over tiles\n",
    "    for tile_id in tqdm(tiles[\"tile_id\"], position=0, leave=True):\n",
    "        \n",
    "        # Read DEM raster based on tile mask\n",
    "        shape = tiles.loc[tiles[\"tile_id\"] == tile_id].geometry.values[0]\n",
    "        with rasterio.open(f\"Z:/Ditches/working/deep_learning/data/dem_1m_wbt/{map_sheet}_dem_1m_wbt.tif\") as src:\n",
    "            out_image, out_transform = rasterio.mask.mask(src, [shape], crop=True)\n",
    "            \n",
    "            # Output metadata\n",
    "            out_meta = src.meta\n",
    "            out_meta.update(\n",
    "                {\n",
    "                    \"height\": out_image.shape[1],\n",
    "                    \"width\": out_image.shape[2],\n",
    "                    \"transform\": out_transform\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Write to GeoTIFF\n",
    "            with rasterio.open(f\"{out_dirpath}/{tile_id}.tif\", \"w\", **out_meta) as dst:\n",
    "                dst.write(out_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02381304-c1e6-47f2-8924-56930df5bf38",
   "metadata": {},
   "source": [
    "## Split vector ditches to tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a930ec03-bce8-4586-870c-b5dd7228eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory\n",
    "out_dirpath = f\"{finetuning_dir}/ditches_vector\"\n",
    "if os.path.exists(out_dirpath):\n",
    "    shutil.rmtree(out_dirpath)\n",
    "os.mkdir(out_dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff2e825a-017e-4598-9061-0d3f06a66e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 94.63it/s]\n",
      "<timed exec>:16: UserWarning: `keep_geom_type=True` in overlay resulted in 2 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 90.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 922 ms\n",
      "Wall time: 953 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Loop over map sheets\n",
    "map_sheets = [53972, 54591]\n",
    "for map_sheet in map_sheets:\n",
    "    \n",
    "    # Read tiles\n",
    "    fp = f\"{finetuning_dir}/{map_sheet}_grid_{grid_size}m_model.gpkg\"\n",
    "    tiles = gpd.read_file(fp)\n",
    "    \n",
    "    # Read digitized ditches\n",
    "    ditches = gpd.read_file(f\"{basepath}/working/deep_learning/data/estonia_digitization/{map_sheet}/{map_sheet}_digitized_ditches.gpkg\")\n",
    "    \n",
    "    # Add ID column\n",
    "    ditches[\"id\"] = ditches.index + 1\n",
    "    \n",
    "    # Intersect ditches with tiles\n",
    "    ditches = gpd.overlay(ditches, tiles, how=\"intersection\")\n",
    "    \n",
    "    # Explode multi-part geometries\n",
    "    ditches = ditches.explode(index_parts=False).reset_index(drop=True)\n",
    "    \n",
    "    # Update ID column\n",
    "    ditches[\"id\"] = ditches.index + 1\n",
    "    \n",
    "    # Group by tile ID and write to GPKG\n",
    "    for tile_id, group in tqdm(ditches.groupby(\"tile_id\"), position=0, leave=True):\n",
    "        group.to_file(f\"{out_dirpath}/{tile_id}.shp\", crs=ditches.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311b0966-6917-418b-a0ab-4ce711448203",
   "metadata": {},
   "source": [
    "## Generate labels\n",
    "\n",
    "Workflow for generating labels from digitized ditches:\n",
    "1. Rasterize ditches based on the bounds of the corresponding DEM file\n",
    "2. Create a binary raster of ditches, where the value 1 to indicates ditch and 0 non-ditch cells\n",
    "3. Generate HPMF raster from DEM file\n",
    "4. Reclassify HPMF values below -0.075 to 1\n",
    "5. Buffer ditches by 3 m\n",
    "6. Extract reclassified HPMF cells based on buffered ditches\n",
    "7. Apply majority filter to buffers to remove spurious masked HPMF cells that are not connected to ditches\n",
    "8. Flag cells that were digitized or are below the HPMF threshold as ditch cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de3d3bd4-1ba9-49db-902e-d9f3806adfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate output directories\n",
    "out_dirpaths= [\n",
    "    f\"{finetuning_dir}/ditches_raster\",\n",
    "    f\"{finetuning_dir}/ditches_reclassified\",\n",
    "    f\"{finetuning_dir}/hpmf\",\n",
    "    f\"{finetuning_dir}/hpmf_reclassified\",\n",
    "    f\"{finetuning_dir}/ditches_buffered\",\n",
    "    f\"{finetuning_dir}/hpmf_masked\",\n",
    "    f\"{finetuning_dir}/ditches_filtered\",\n",
    "    f\"{finetuning_dir}/labels\"\n",
    "]\n",
    "for out_dirpath in out_dirpaths:\n",
    "    if os.path.exists(out_dirpath):\n",
    "        shutil.rmtree(out_dirpath)\n",
    "    os.mkdir(out_dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "440ebd9d-9510-4489-bd09-97eac779174c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 72/72 [00:38<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.36 s\n",
      "Wall time: 38.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Loop over vector ditches\n",
    "ditches_vector_files = glob.glob(f\"{finetuning_dir}/ditches_vector/*.shp\")\n",
    "for ditches_vector_file in tqdm(ditches_vector_files, position=0, leave=True):\n",
    "    \n",
    "    tile_id = os.path.basename(ditches_vector_file).split(\".\")[0]\n",
    "    \n",
    "    # Rasterize ditches\n",
    "    field = \"id\"\n",
    "    nodata = 0\n",
    "    whitebox.vector_lines_to_raster(\n",
    "        f\"{finetuning_dir}/ditches_vector/{tile_id}.shp\",\n",
    "        f\"{finetuning_dir}/ditches_raster/{tile_id}.tif\",\n",
    "        field=field,\n",
    "        nodata=nodata,\n",
    "        base=f\"{finetuning_dir}/dem/{tile_id}.tif\"\n",
    "    )\n",
    "    \n",
    "    # Assign new value to ditch cells\n",
    "    new_value = 1.0\n",
    "    from_value = 1\n",
    "    to_less_than = ditches[\"id\"].max() + 1\n",
    "    reclass_vals = f\"{new_value};{from_value};{to_less_than}\"\n",
    "    whitebox.reclass(\n",
    "        f\"{finetuning_dir}/ditches_raster/{tile_id}.tif\",\n",
    "        f\"{finetuning_dir}/ditches_reclassified/{tile_id}.tif\",\n",
    "        reclass_vals\n",
    "    )\n",
    "\n",
    "    # Generate HPMF raster\n",
    "    filterx = 5\n",
    "    filtery = 5\n",
    "    whitebox.high_pass_median_filter(\n",
    "        f\"{finetuning_dir}/dem/{tile_id}.tif\",\n",
    "        f\"{finetuning_dir}/hpmf/{tile_id}.tif\",\n",
    "        filterx=filterx,\n",
    "        filtery=filtery,\n",
    "        sig_digits=2\n",
    "    )\n",
    "\n",
    "    # Reclassify HPMF values below -0.075 to 1\n",
    "    threshold = -0.075\n",
    "    whitebox.less_than(\n",
    "        f\"{finetuning_dir}/hpmf/{tile_id}.tif\",\n",
    "        threshold,\n",
    "        f\"{finetuning_dir}/hpmf_reclassified/{tile_id}.tif\"\n",
    "    )\n",
    "\n",
    "    # Buffer ditches by 3 m\n",
    "    input = f\"{finetuning_dir}/ditches_reclassified/{tile_id}.tif\"\n",
    "    buff_size_m = 3\n",
    "    cell_size_m = rasterio.open(input).res[0]\n",
    "    size = int(buff_size_m / cell_size_m)\n",
    "    whitebox.buffer_raster(\n",
    "        input,\n",
    "        f\"{finetuning_dir}/ditches_buffered/{tile_id}.tif\",\n",
    "        str(size)\n",
    "    )\n",
    "\n",
    "    # Extract reclassified HPMF cells based on buffered ditches\n",
    "    whitebox.multiply(\n",
    "        f\"{finetuning_dir}/hpmf_reclassified/{tile_id}.tif\",\n",
    "        f\"{finetuning_dir}/ditches_buffered/{tile_id}.tif\",\n",
    "        f\"{finetuning_dir}/hpmf_masked/{tile_id}.tif\"\n",
    "    )\n",
    "\n",
    "    # Apply majority filter\n",
    "    filterx = 3\n",
    "    filtery = 3\n",
    "    whitebox.majority_filter(\n",
    "        f\"{finetuning_dir}/hpmf_masked/{tile_id}.tif\",\n",
    "        f\"{finetuning_dir}/ditches_filtered/{tile_id}.tif\",\n",
    "        filterx=filterx,\n",
    "        filtery=filtery\n",
    "    )\n",
    "\n",
    "    # Flag cells that were digitized or are below the HPMF threshold as ditch cells\n",
    "    whitebox.Or(\n",
    "        f\"{finetuning_dir}/ditches_reclassified/{tile_id}.tif\",\n",
    "        f\"{finetuning_dir}/ditches_filtered/{tile_id}.tif\",\n",
    "        f\"{finetuning_dir}/labels/{tile_id}.tif\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc624162-930c-49fd-9f17-dcf8659794ca",
   "metadata": {},
   "source": [
    "## Normalize HPMF rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcc28fdd-ad95-4afb-b5c2-755a77917879",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read HPMF statistics\n",
    "stats_df = pd.read_csv(f\"{basepath}/working/deep_learning/data/dem_1m_hpmf_stats.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05bfe1af-753a-4d55-9916-24bd5a0671aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>hpmf_min</th>\n",
       "      <th>hpmf_max</th>\n",
       "      <th>hpmf_mean</th>\n",
       "      <th>hpmf_percentile_1</th>\n",
       "      <th>hpmf_percentile_10</th>\n",
       "      <th>hpmf_percentile_90</th>\n",
       "      <th>hpmf_percentile_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:/users/holgerv/Ditches/working/deep_learning...</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>-0.390000</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:/users/holgerv/Ditches/working/deep_learning...</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>-0.440000</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:/users/holgerv/Ditches/working/deep_learning...</td>\n",
       "      <td>-1.66</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>-0.470000</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:/users/holgerv/Ditches/working/deep_learning...</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.004625</td>\n",
       "      <td>-0.410000</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:/users/holgerv/Ditches/working/deep_learning...</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.006886</td>\n",
       "      <td>-0.410000</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>D:/users/holgerv/Ditches/working/deep_learning...</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.008336</td>\n",
       "      <td>-0.310000</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>D:/users/holgerv/Ditches/working/deep_learning...</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>-0.330000</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>D:/users/holgerv/Ditches/working/deep_learning...</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>-0.290000</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>D:/users/holgerv/Ditches/working/deep_learning...</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.006919</td>\n",
       "      <td>-0.340000</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>D:/users/holgerv/Ditches/working/deep_learning...</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.009452</td>\n",
       "      <td>-0.372185</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2073 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   file  hpmf_min  hpmf_max  \\\n",
       "0     D:/users/holgerv/Ditches/working/deep_learning...     -0.76      0.93   \n",
       "1     D:/users/holgerv/Ditches/working/deep_learning...     -1.90      1.08   \n",
       "2     D:/users/holgerv/Ditches/working/deep_learning...     -1.66      1.62   \n",
       "3     D:/users/holgerv/Ditches/working/deep_learning...     -1.50      1.44   \n",
       "4     D:/users/holgerv/Ditches/working/deep_learning...     -0.96      2.30   \n",
       "...                                                 ...       ...       ...   \n",
       "2068  D:/users/holgerv/Ditches/working/deep_learning...     -0.52      0.81   \n",
       "2069  D:/users/holgerv/Ditches/working/deep_learning...     -0.98      1.09   \n",
       "2070  D:/users/holgerv/Ditches/working/deep_learning...     -0.65      0.78   \n",
       "2071  D:/users/holgerv/Ditches/working/deep_learning...     -0.58      0.41   \n",
       "2072  D:/users/holgerv/Ditches/working/deep_learning...     -0.58      0.94   \n",
       "\n",
       "      hpmf_mean  hpmf_percentile_1  hpmf_percentile_10  hpmf_percentile_90  \\\n",
       "0      0.000417          -0.390000               -0.24               -0.09   \n",
       "1      0.000589          -0.440000               -0.25               -0.09   \n",
       "2      0.002162          -0.470000               -0.31               -0.10   \n",
       "3      0.004625          -0.410000               -0.25               -0.09   \n",
       "4      0.006886          -0.410000               -0.21               -0.09   \n",
       "...         ...                ...                 ...                 ...   \n",
       "2068   0.008336          -0.310000               -0.18               -0.09   \n",
       "2069   0.003026          -0.330000               -0.15               -0.08   \n",
       "2070   0.002513          -0.290000               -0.16               -0.08   \n",
       "2071   0.006919          -0.340000               -0.18               -0.09   \n",
       "2072   0.009452          -0.372185               -0.21               -0.11   \n",
       "\n",
       "      hpmf_percentile_99  \n",
       "0                  -0.09  \n",
       "1                  -0.09  \n",
       "2                  -0.10  \n",
       "3                  -0.09  \n",
       "4                  -0.09  \n",
       "...                  ...  \n",
       "2068               -0.09  \n",
       "2069               -0.08  \n",
       "2070               -0.07  \n",
       "2071               -0.09  \n",
       "2072               -0.10  \n",
       "\n",
       "[2073 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa332987-f91c-4323-8fc9-fff3e69b7396",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2073.000000\n",
       "mean       -1.237062\n",
       "std         0.735341\n",
       "min       -18.440000\n",
       "1%         -4.028800\n",
       "50%        -1.090000\n",
       "max        -0.110000\n",
       "Name: hpmf_min, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df[\"hpmf_min\"].describe(percentiles=[0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "100a67cc-840f-4b61-9990-c1392f64e427",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2073.000000\n",
       "mean        1.482142\n",
       "std         1.000186\n",
       "min         0.090000\n",
       "50%         1.260000\n",
       "99%         5.249200\n",
       "max        14.690000\n",
       "Name: hpmf_max, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df[\"hpmf_max\"].describe(percentiles=[0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "677ef89a-2bbd-4446-ae44-c957983b28d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get lower HPMF boundary based on first percentile of minimum values\n",
    "lower_boundary = stats_df[\"hpmf_min\"].describe(percentiles=[0.01])[\"1%\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83464520-500c-40fc-8c97-0e1cb7962d16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get upper HPMF boundary based on 99th percentile of maximum values\n",
    "upper_boundary = stats_df[\"hpmf_max\"].describe(percentiles=[0.99])[\"99%\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfe4e229-ff33-4f23-b78c-c4afe83c2dfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.0288"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5.249200000000028"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(lower_boundary)\n",
    "display(upper_boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "079aade6-9000-4495-949a-8ee8e03986c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize HPMF raster\n",
    "def normalize_hpmf_raster(in_fp: str, lower_boundary: float, upper_boundary: float, out_fp: str):\n",
    "    \n",
    "    with rasterio.open(in_fp) as src:\n",
    "        \n",
    "        # Read array\n",
    "        array = src.read(1)\n",
    "        \n",
    "        # Get profile\n",
    "        out_profile = src.profile\n",
    "        \n",
    "        # Replace no data values\n",
    "        out_nodata = np.nan\n",
    "        array = np.where(array == out_profile[\"nodata\"], np.nan, array)\n",
    "        \n",
    "        # Cap outliers below lower boundary\n",
    "        array = np.where(array <= lower_boundary, lower_boundary, array)\n",
    "        \n",
    "        # Cap outliers above upper boundary\n",
    "        array = np.where(array >= upper_boundary, upper_boundary, array)\n",
    "        \n",
    "        # Normalize based on lower and upper boundaries\n",
    "        array_norm = (array - lower_boundary) / (upper_boundary - lower_boundary)\n",
    "        \n",
    "        # Update profile\n",
    "        out_profile[\"nodata\"] = out_nodata\n",
    "        \n",
    "        # Write to raster\n",
    "        with rasterio.open(out_fp, \"w\", **out_profile) as dst:\n",
    "            dst.write(array_norm, 1)\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ceae57e7-2365-4fe5-9634-bd53da5241d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory\n",
    "out_dirpath = f\"{finetuning_dir}/hpmf_norm\"\n",
    "if os.path.exists(out_dirpath):\n",
    "    shutil.rmtree(out_dirpath)\n",
    "os.mkdir(out_dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cce7a84-9edb-4b4f-9e2b-161724663af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 72/72 [00:01<00:00, 36.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.95 s\n",
      "Wall time: 1.95 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Loop over HPMF files and normalize them\n",
    "files = glob.glob(f\"{finetuning_dir}/hpmf/*.tif\")\n",
    "for file in tqdm(files, position=0, leave=True):\n",
    "    out_fp = f\"{out_dirpath}/{os.path.basename(file)}\"\n",
    "    normalize_hpmf_raster(file, lower_boundary, upper_boundary, out_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a2c0b0-b477-4507-be86-de7e5ed459f2",
   "metadata": {},
   "source": [
    "## Split data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78132b29-eb42-4545-903c-39b7cb675715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input HPMF files\n",
    "fp_hpmf_list = sorted(glob.glob(f\"{finetuning_dir}/hpmf_norm/*.tif\"))\n",
    "hpmf_files = [os.path.basename(fp_hpmf) for fp_hpmf in fp_hpmf_list]\n",
    "\n",
    "# Input labels\n",
    "fp_labels_list = sorted(glob.glob(f\"{finetuning_dir}/labels/*.tif\"))\n",
    "labels_files = [os.path.basename(fp_labels) for fp_labels in fp_labels_list]\n",
    "\n",
    "# Loop over labels and collect matching image pairs\n",
    "image_pairs = {}\n",
    "for i in range(len(labels_files)):\n",
    "    labels_file = labels_files[i]\n",
    "    if labels_file in hpmf_files:\n",
    "        fp_hpmf = glob.glob(f\"{finetuning_dir}/hpmf_norm/{labels_file}\")[0]\n",
    "        fp_labels = glob.glob(f\"{finetuning_dir}/labels/{labels_file}\")[0]\n",
    "        image_pairs[fp_hpmf] = fp_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0aa8e20-e38f-4eb0-9b5a-0fc8a8fdf436",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_train = 0.8\n",
    "pct_test = 1 - pct_train\n",
    "n_samples = len(image_pairs)\n",
    "n_train = round(n_samples * pct_train)\n",
    "n_test = n_samples - n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d14d314-6398-48a8-9e0e-db6c8c31f765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 14)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train, n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30d13bf9-6dd9-43ba-a0e1-c933c0a19729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split HPMF files into training and test samples\n",
    "random.seed(0)\n",
    "fp_hpmf_list_train = random.sample(list(image_pairs.keys()), n_train)\n",
    "fp_hpmf_list_test = [file for file in list(image_pairs.keys()) if file not in fp_hpmf_list_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca01c650-e27d-424b-aa83-969daa302c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 14)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fp_hpmf_list_train), len(fp_hpmf_list_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a6cd2d-0201-44ab-820f-0be4646317b0",
   "metadata": {},
   "source": [
    "### Generate training data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68c875b2-3ab9-407d-a9b5-c63843302dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directories\n",
    "out_dir = f\"{finetuning_dir}/training\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "out_dir_hpmf = f\"{out_dir}/hpmf\"\n",
    "if os.path.exists(out_dir_hpmf):\n",
    "    shutil.rmtree(out_dir_hpmf)\n",
    "os.mkdir(out_dir_hpmf)\n",
    "out_dir_labels = f\"{out_dir}/labels\"\n",
    "if os.path.exists(out_dir_labels):\n",
    "    shutil.rmtree(out_dir_labels)\n",
    "os.mkdir(out_dir_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7769b09a-ba5f-4606-82e2-9d7b1eacc12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 78.1 ms\n",
      "Wall time: 475 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Copy image pairs to corresponding directories\n",
    "for fp_hpmf in fp_hpmf_list_train:\n",
    "    fp_labels = image_pairs[fp_hpmf]\n",
    "    shutil.copy(fp_hpmf, out_dir_hpmf)\n",
    "    shutil.copy(fp_labels, out_dir_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97e61638-83f5-4342-b522-accc05b475cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(out_dir_hpmf)) == n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0285f55-1337-4df4-b194-9b5ba20e80d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(out_dir_labels)) == n_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5f645c-1446-4f27-baf9-4377139893df",
   "metadata": {},
   "source": [
    "### Generate test data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e23a9da3-3790-401d-8cc2-985e250d1972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directories\n",
    "out_dir = f\"{finetuning_dir}/testing\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "out_dir_hpmf = f\"{out_dir}/hpmf\"\n",
    "if os.path.exists(out_dir_hpmf):\n",
    "    shutil.rmtree(out_dir_hpmf)\n",
    "os.mkdir(out_dir_hpmf)\n",
    "out_dir_labels = f\"{out_dir}/labels\"\n",
    "if os.path.exists(out_dir_labels):\n",
    "    shutil.rmtree(out_dir_labels)\n",
    "os.mkdir(out_dir_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "234d080c-6ec1-4eaf-aaa5-e3b83e8fffc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 80.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Copy image pairs to corresponding directories\n",
    "for fp_hpmf in fp_hpmf_list_test:\n",
    "    fp_labels = image_pairs[fp_hpmf]\n",
    "    shutil.copy(fp_hpmf, out_dir_hpmf)\n",
    "    shutil.copy(fp_labels, out_dir_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be0a5400-e630-4c42-bc29-9c8c40312554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(out_dir_hpmf)) == n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85b81274-bf17-4d13-acba-ce21aa213076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(out_dir_labels)) == n_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ditches",
   "language": "python",
   "name": "ditches"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
